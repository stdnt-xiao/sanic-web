import json
import warnings

warnings.filterwarnings("ignore", category=UserWarning, module="jieba")

import logging
import re
from typing import Dict, List, Any, Optional
import jieba
import pandas as pd
from sqlalchemy.inspection import inspect
from sqlalchemy.sql.expression import text
from rank_bm25 import BM25Okapi
from agent.text2sql.state.agent_state import AgentState, ExecutionResult
from model.db_connection_pool import get_db_pool
from functools import lru_cache

# è·å–æ•°æ®åº“è¿æ¥æ± ï¼ˆå…¨å±€ï¼‰
db_pool = get_db_pool()
logger = logging.getLogger(__name__)


class DatabaseService:
    """
    æ•°æ®åº“æœåŠ¡ç±»ï¼šè´Ÿè´£è·å–è¡¨ç»“æ„ã€åŸºäºç”¨æˆ·æŸ¥è¯¢ç­›é€‰ç›¸å…³è¡¨ã€æ‰§è¡ŒSQLç­‰ã€‚
    """

    def __init__(self):
        self._engine = db_pool.get_engine()

    @staticmethod
    def _tokenize_text(text_str: str) -> List[str]:
        """
        :param text_str
        https://github.com/fxsjy/jieba
        å¯¹æ–‡æœ¬è¿›è¡Œä¸­æ–‡/è‹±æ–‡åˆ†è¯ï¼Œè¿‡æ»¤æ ‡ç‚¹ç¬¦å·ã€‚
        """
        filtered_text = re.sub(r"[^\u4e00-\u9fa5a-zA-Z0-9]", " ", text_str)
        tokens = jieba.lcut(filtered_text, cut_all=False)
        # print(tokens)
        return [token.strip() for token in tokens if token.strip()]

    def _get_table_comment(self, table_name: str) -> str:
        """
        ä» information_schema è·å– MySQL è¡¨æ³¨é‡Šã€‚
        """
        try:
            query = text(
                """
                SELECT table_comment 
                FROM information_schema.tables 
                WHERE table_schema = DATABASE() 
                  AND table_name = :table_name;
            """
            )
            with self._engine.connect() as conn:
                result = conn.execute(query, {"table_name": table_name})
                row = result.fetchone()
                return row[0].strip() if row else ""
        except Exception as e:
            logger.warning(f"æ— æ³•è·å–è¡¨ {table_name} çš„æ³¨é‡Š: {e}")
            return ""

    @staticmethod
    def _build_document(table_name: str, table_info: dict) -> str:
        """
        æ„å»ºç”¨äº BM25 åŒ¹é…çš„æ–‡æ¡£æ–‡æœ¬ã€‚
        """
        parts = [table_name]

        # æ·»åŠ è¡¨æ³¨é‡Š
        table_comment = table_info.get("table_comment", "")
        if table_comment:
            parts.append(table_comment)

        # æ·»åŠ åˆ—ä¿¡æ¯ï¼šåˆ—å + ä¸­æ–‡å + æ³¨é‡Š
        for col_name, col_info in table_info.get("columns", {}).items():
            parts.append(col_name)
            # parts.append(col_info.get("cn_name", ""))
            parts.append(col_info.get("comment", ""))

        return " ".join(parts)

    @lru_cache(maxsize=1)  # ç¼“å­˜æ•´ä¸ª schemaï¼Œä»…å½“æ•°æ®åº“ä¸å˜æ—¶æœ‰æ•ˆ
    def _fetch_all_table_info(self) -> Dict[str, Dict]:
        """
        ä»æ•°æ®åº“è·å–æ‰€æœ‰è¡¨çš„ç»“æ„ä¿¡æ¯ï¼ˆå¸¦ç¼“å­˜ï¼‰ã€‚
        """
        inspector = inspect(self._engine)
        table_info = {}

        for table_name in inspector.get_table_names():
            try:
                # è·å–åˆ—ä¿¡æ¯
                columns = {}
                for col in inspector.get_columns(table_name):
                    comment = str(col["comment"] or "")
                    columns[col["name"]] = {
                        "type": str(col["type"]),
                        "comment": comment,
                        # "cn_name": comment,
                    }

                # è·å–å¤–é”®
                foreign_keys = [
                    f"{fk['constrained_columns'][0]} -> {fk['referred_table']}.{fk['referred_columns'][0]}"
                    for fk in inspector.get_foreign_keys(table_name)
                ]

                # è·å–è¡¨æ³¨é‡Š
                table_comment = self._get_table_comment(table_name)

                table_info[table_name] = {
                    "columns": columns,
                    "foreign_keys": foreign_keys,
                    "table_comment": table_comment,
                }
            except Exception as e:
                logger.warning(f"è¯»å–è¡¨ {table_name} ç»“æ„å¤±è´¥: {e}")

        logger.info(f"æˆåŠŸåŠ è½½ {len(table_info)} å¼ è¡¨çš„ schema ä¿¡æ¯")
        return table_info

    def _filter_relevant_tables_by_bm25(self, table_info: Dict[str, Dict], user_query: str) -> Dict[str, Dict]:
        """
        ä½¿ç”¨ BM25 ç®—æ³•ç­›é€‰ä¸ç”¨æˆ·æŸ¥è¯¢æœ€ç›¸å…³çš„è¡¨ã€‚
        """
        if not user_query or not table_info:
            return table_info

        # æ„å»ºè¯­æ–™
        corpus = []
        table_names = []
        table_comments = []

        for table_name, info in table_info.items():
            doc = self._build_document(table_name, info)
            corpus.append(doc)
            table_names.append(table_name)
            table_comments.append(info.get("table_comment", ""))

        # åˆ†è¯
        tokenized_corpus = [self._tokenize_text(doc) for doc in corpus]
        query_tokens = self._tokenize_text(user_query)
        query_token_set = set(query_tokens)

        # è®­ç»ƒ BM25 æ¨¡å‹
        bm25 = BM25Okapi(tokenized_corpus)
        doc_scores = bm25.get_scores(query_tokens)

        # åŠ¨æ€å¢å¼ºï¼šå¦‚æœè¡¨æ³¨é‡Šä¸æŸ¥è¯¢æœ‰å…³é”®è¯é‡å ï¼Œåˆ™ææƒ
        enhanced_scores = doc_scores.copy()
        for i, (comment, score) in enumerate(zip(table_comments, doc_scores)):
            if score <= 0:
                continue
            comment_tokens = self._tokenize_text(comment)
            comment_token_set = set(comment_tokens)
            overlap = query_token_set & comment_token_set
            if overlap:
                # æ ¹æ®é‡å æ¯”ä¾‹ææƒ
                overlap_ratio = len(overlap) / len(query_token_set)
                enhanced_scores[i] += score * overlap_ratio * 1.5  # æå‡æƒé‡

        # ä½¿ç”¨å¢å¼ºåå¾—åˆ†æ’åº
        scored_tables = sorted(
            [(idx, score) for idx, score in enumerate(enhanced_scores)],
            key=lambda x: x[1],
            reverse=True,
        )

        # è¾“å‡ºæŸ¥è¯¢å’Œå¾—åˆ†æ—¥å¿—
        print(f"\nğŸ” æŸ¥è¯¢: {user_query}")
        for idx, score in scored_tables[:5]:
            table_name = table_names[idx]
            print(f" âœ… {table_name:12} | å¾—åˆ†: {score:.4f}")

        # åŠ¨æ€é˜ˆå€¼ï¼šä¿ç•™å¾—åˆ† > æœ€é«˜åˆ† 10% çš„è¡¨ï¼Œæœ€å¤šè¿”å› 5 ä¸ª
        if not scored_tables:
            return {}

        max_score = scored_tables[0][1]
        threshold = max(max_score * 0.1, 0.5)  # è‡³å°‘ 0.5 æˆ– 10%
        top_indices = [i for i, s in scored_tables if s >= threshold][:5]

        filtered_table_info = {table_names[idx]: table_info[table_names[idx]] for idx in top_indices}

        logger.info(f"BM25 ç­›é€‰å‡º {len(filtered_table_info)} ä¸ªç›¸å…³è¡¨: {list(filtered_table_info.keys())}")
        return filtered_table_info

    def get_table_schema(self, state: AgentState) -> AgentState:
        """
        è·å–æ•°æ®åº“è¡¨ç»“æ„ï¼Œå¹¶æ ¹æ®ç”¨æˆ·æŸ¥è¯¢ç­›é€‰ç›¸å…³è¡¨ã€‚
        """
        try:
            logger.info("å¼€å§‹è·å–æ•°æ®åº“è¡¨ schema ä¿¡æ¯")

            # è·å–å…¨éƒ¨è¡¨ç»“æ„ï¼ˆå¸¦ç¼“å­˜ï¼‰
            all_table_info = self._fetch_all_table_info()

            user_query = state.get("user_query", "").strip()

            # æ ¹æ®æŸ¥è¯¢ç­›é€‰ç›¸å…³è¡¨
            if user_query:
                filtered_info = self._filter_relevant_tables_by_bm25(all_table_info, user_query)
                state["db_info"] = filtered_info
            else:
                state["db_info"] = all_table_info

            logger.info(f"è·å–æ•°æ®åº“è¡¨ä¿¡æ¯æˆåŠŸï¼Œå…± {len(state['db_info'])} å¼ è¡¨")
        except Exception as e:
            logger.error(f"è·å–æ•°æ®åº“è¡¨ä¿¡æ¯å¤±è´¥: {e}", exc_info=True)
            state["db_info"] = {}
            state["execution_result"] = ExecutionResult(success=False, error="æ— æ³•è¿æ¥æ•°æ®åº“æˆ–è·å–å…ƒæ•°æ®")

        return state

    @staticmethod
    def execute_sql(state: AgentState) -> AgentState:
        """
        æ‰§è¡Œç”Ÿæˆçš„ SQL è¯­å¥ã€‚
        """
        generated_sql = state.get("generated_sql", "").strip()
        if not generated_sql:
            state["execution_result"] = ExecutionResult(success=False, error="SQL ä¸ºç©º")
            return state

        logger.info("æ‰§è¡Œ SQL è¯­å¥")
        try:
            with db_pool.get_session() as connection:
                # é˜²æ­¢å¤§ç»“æœé›†ï¼Œè‡ªåŠ¨æ·»åŠ  LIMIT
                result = connection.execute(text(generated_sql))
                result_data = result.fetchall()
                columns = result.keys()
                frame = pd.DataFrame(result_data, columns=columns)

                state["execution_result"] = ExecutionResult(
                    success=True,
                    data=frame.to_dict(orient="records"),
                )
        except Exception as e:
            logger.error(f"æ‰§è¡Œ SQL å¤±è´¥: {e}", exc_info=True)
            state["execution_result"] = ExecutionResult(success=False, error=str(e))

        return state

    @staticmethod
    def execute_correction_sql(state: AgentState) -> AgentState:
        """
        æ‰§è¡Œä¿®æ­£åçš„ SQL è¯­å¥ã€‚
        """
        correction_result = state.get("correction_result")
        if not correction_result or not hasattr(correction_result, "corrected_sql_query"):
            state["execution_result"] = ExecutionResult(success=False, error="æ— ä¿®æ­£åçš„ SQL å¯æ‰§è¡Œ")
            return state

        corrected_sql = correction_result.corrected_sql_query.strip()
        if not corrected_sql:
            state["execution_result"] = ExecutionResult(success=False, error="ä¿®æ­£åçš„ SQL ä¸ºç©º")
            return state

        logger.info("æ‰§è¡Œä¿®æ­£åçš„ SQL è¯­å¥")
        try:
            with db_pool.get_session() as connection:
                result = connection.execute(text(corrected_sql))
                result_data = result.fetchall()
                columns = result.keys()
                frame = pd.DataFrame(result_data, columns=columns)

                state["execution_result"] = ExecutionResult(
                    success=True,
                    data=frame.to_dict(orient="records"),
                )
        except Exception as e:
            logger.error(f"æ‰§è¡Œä¿®æ­£ SQL å¤±è´¥: {e}", exc_info=True)
            state["execution_result"] = ExecutionResult(success=False, error=str(e))

        return state
