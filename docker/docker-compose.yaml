version: '3.8'

services:
  chat-web:
#    image: apconw/chat-vue3-mvp:1.1.5
    image: crpi-7xkxsdc0iki61l0q.cn-hangzhou.personal.cr.aliyuncs.com/apconw/chat-vue3-mvp:1.1.8
    container_name: chat-vue3-mvp
    environment:
      - TZ=Asia/Shanghai
    volumes:
      - ./nginx.conf:/etc/nginx/conf.d/nginx.conf
    ports:
      - "8081:80"
    extra_hosts:
      - "host.docker.internal:host-gateway"
    depends_on:
      - chat-service

  minio:
    image: minio/minio:RELEASE.2025-04-22T22-12-26Z
    container_name: minio
    ports:
      - "19000:9000"
      - "19001:9001"
    volumes:
      - ./volume/minio/data:/data
    environment:
      - MINIO_ROOT_USER=admin
      - MINIO_ROOT_PASSWORD=12345678
    command: server /data --console-address ":9001"

  chat-service:
#    image: apconw/sanic-web:1.1.5
    image: crpi-7xkxsdc0iki61l0q.cn-hangzhou.personal.cr.aliyuncs.com/apconw/sanic-web:1.1.8
    container_name: sanic-web
    environment:
      - MYSQL_HOST=host.docker.internal
      - MYSQL_PORT=13006
      - MYSQL_USER=root
      - MYSQL_PASSWORD=1
      - MYSQL_DATABASE=chat_db
      - SQLALCHEMY_DATABASE_URI=mysql+pymysql://root:1@host.docker.internal:13006/chat_db
      - DIFY_SERVER_URL=http://host.docker.internal:18000
      - DIFY_DATABASE_QA_API_KEY=app-GIz9dM9GPUXVZOkDRaC0TOxh
      - MINIO_ENDPOINT=host.docker.internal:19000
      - MINIO_ACCESS_KEY=I1S0ASDRGS2TWA3bG392
      - MiNIO_SECRET_KEY=jk8Ma61GbEMATk8FeAuxD8apgK2l7dCsker6yT5R
      - MODEL_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1
      - MODEL_NAME=qwen-plus
      - MODEL_TEMPERATURE=0.75
      - MODEL_API_KEY=sk-xxxx
      - MCP_HUB_COMMON_QA_GROUP_URL=http://host.docker.internal:3300/mcp/fa7646b4-1679-4d1d-9bda-3e9190cfef1a
      - MCP_HUB_DATABASE_QA_GROUP_URL=http://host.docker.internal:3300/mcp/f635fd21-2f44-4a99-8a92-f778b4d3607f
      - SHOW_THINKING_PROCESS=true
      - NEO4J_URI=bolt://host.docker.internal:7687
      - NEO4J_USER=neo4j
      - NEO4J_PASSWORD=neo4j123
      - TZ=Asia/Shanghai
    ports:
      - "8088:8088"
    extra_hosts:
      - "host.docker.internal:host-gateway"

  mysql:
    image: mysql:latest
    container_name: chat-db
    ports:
      - "13006:3306"
    environment:
      - MYSQL_ROOT_PASSWORD=1
      - CHARACTER_SET_SERVER=utf8mb4
      - COLLATION_SERVER=utf8mb4_unicode_ci
      - TZ=Asia/Shanghai
    volumes:
      - ./volume/mysql/data:/var/lib/mysql
      - ./my.cnf:/etc/mysql/conf.d/my.cnf

  mcphub:
    image: samanhappy/mcphub:0.9.0
    container_name: mcphub
    ports:
      - "3300:3000"
    volumes:
      - ./volume/mcp-data/mcp_settings.json:/app/mcp_settings.json
      - ./volume/mcp-data/data:/app/data
    extra_hosts:
      - "host.docker.internal:host-gateway"

  gpt-vis-api:
    image: crpi-7xkxsdc0iki61l0q.cn-hangzhou.personal.cr.aliyuncs.com/apconw/gpt-vis-api:0.0.1
    container_name: gpt-vis-api
    ports:
      - "3100:3000"
    environment:
      MINIO_ENDPOINT: host.docker.internal
      MINIO_PORT: 19000
      MINIO_USE_SSL: "false"
      MINIO_ACCESS_KEY: v2Kn9q5zeXX8orpITc2p
      MINIO_SECRET_KEY: MwZlHLJKnrb83gnfgSQBpPCoTsOZT2SwURG2tx02
      MINIO_BUCKET: chart-images
      MINIO_PUBLIC_DOMAIN: "http://localhost:19000"
    extra_hosts:
      - "host.docker.internal:host-gateway"

  neo4j-apoc:
    image: neo4j:5.26.11-ubi9
    container_name: neo4j-apoc
    ports:
      - "7474:7474"
      - "7687:7687"
    volumes:
      - ./volume/neo4j/data:/data
      - ./volume/neo4j/plugins:/plugins
    environment:
      - apoc.export.file.enabled=true
      - apoc.import.file.enabled=true
      - apoc.import.file.use_neo4j_config=true
      - NEO4J_AUTH=neo4j/neo4j123

  mineru-vllm-server:
    image: mineru-vllm:latest
    container_name: mineru-vllm-server
    restart: always
    profiles: ["vllm-server"]
    ports:
      - 30000:30000
    environment:
      MINERU_MODEL_SOURCE: local
    entrypoint: mineru-vllm-server
    command:
      --host 0.0.0.0
      --port 30000
      # --data-parallel-size 2  # If using multiple GPUs, increase throughput using vllm's multi-GPU parallel mode
      # --gpu-memory-utilization 0.5  # If running on a single GPU and encountering VRAM shortage, reduce the KV cache size by this parameter, if VRAM issues persist, try lowering it further to `0.4` or below.
    ulimits:
      memlock: -1
      stack: 67108864
    ipc: host
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:30000/health || exit 1"]
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["0"]
              capabilities: [gpu]

  mineru-api:
    image: mineru-vllm:latest
    container_name: mineru-api
    restart: always
    profiles: ["api"]
    ports:
      - 8000:8000
    environment:
      MINERU_MODEL_SOURCE: local
    entrypoint: mineru-api
    command:
      --host 0.0.0.0
      --port 8000
      # parameters for vllm-engine
      # --data-parallel-size 2  # If using multiple GPUs, increase throughput using vllm's multi-GPU parallel mode
      # --gpu-memory-utilization 0.5  # If running on a single GPU and encountering VRAM shortage, reduce the KV cache size by this parameter, if VRAM issues persist, try lowering it further to `0.4` or below.
    ulimits:
      memlock: -1
      stack: 67108864
    ipc: host
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: [ "0" ]
              capabilities: [ gpu ]

  mineru-gradio:
    image: mineru-vllm:latest
    container_name: mineru-gradio
    restart: always
    profiles: ["gradio"]
    ports:
      - 7860:7860
    environment:
      MINERU_MODEL_SOURCE: local
    entrypoint: mineru-gradio
    command:
      --server-name 0.0.0.0
      --server-port 7860
      --enable-vllm-engine true  # Enable the vllm engine for Gradio
      # --enable-api false  # If you want to disable the API, set this to false
      # --max-convert-pages 20  # If you want to limit the number of pages for conversion, set this to a specific number
      # parameters for vllm-engine
      # --data-parallel-size 2  # If using multiple GPUs, increase throughput using vllm's multi-GPU parallel mode
      # --gpu-memory-utilization 0.5  # If running on a single GPU and encountering VRAM shortage, reduce the KV cache size by this parameter, if VRAM issues persist, try lowering it further to `0.4` or below.
    ulimits:
      memlock: -1
      stack: 67108864
    ipc: host
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: [ "0" ]
              capabilities: [ gpu ]
